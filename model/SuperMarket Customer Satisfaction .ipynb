{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d29d6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "# warning filter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sqlalchemy # sql connection\n",
    "\n",
    "#To Traceback error\n",
    "import traceback\n",
    "\n",
    "# For calculating Time required to run the model\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ploting libraries\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#feature engineering\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import OrdinalEncoder    # Used when you want to provide dictionary    \n",
    "\n",
    "#train test split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Scaling Down\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a1b35106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement Datapreprocessing (from versions: none)\n",
      "ERROR: No matching distribution found for Datapreprocessing\n"
     ]
    }
   ],
   "source": [
    "pip install Datapreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "618b77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Use for Handaling Outliers\n",
    "# from learn.processing import DataPreProcessing\n",
    "\n",
    "# # For All Regressor Models\n",
    "# from learn.supervised import Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1f288df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = []\n",
    "Testing_accuracy = []\n",
    "Training_accuracy = []\n",
    "Testing_Recall = []\n",
    "Testing_Precision = []\n",
    "Testing_F1_Score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "afaa8709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice ID</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>Customer type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Product line</th>\n",
       "      <th>Unit price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Tax 5%</th>\n",
       "      <th>Total</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Payment</th>\n",
       "      <th>cogs</th>\n",
       "      <th>gross margin percentage</th>\n",
       "      <th>gross income</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750-67-8428</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>548.9715</td>\n",
       "      <td>1/5/2019</td>\n",
       "      <td>13:08</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>522.83</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226-31-3081</td>\n",
       "      <td>C</td>\n",
       "      <td>Naypyitaw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>80.2200</td>\n",
       "      <td>3/8/2019</td>\n",
       "      <td>10:29</td>\n",
       "      <td>Cash</td>\n",
       "      <td>76.40</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Invoice ID Branch       City Customer type  Gender  \\\n",
       "0  750-67-8428      A     Yangon        Member  Female   \n",
       "1  226-31-3081      C  Naypyitaw        Normal  Female   \n",
       "\n",
       "             Product line  Unit price  Quantity   Tax 5%     Total      Date  \\\n",
       "0       Health and beauty       74.69         7  26.1415  548.9715  1/5/2019   \n",
       "1  Electronic accessories       15.28         5   3.8200   80.2200  3/8/2019   \n",
       "\n",
       "    Time  Payment    cogs  gross margin percentage  gross income  Rating  \n",
       "0  13:08  Ewallet  522.83                 4.761905       26.1415     9.1  \n",
       "1  10:29     Cash   76.40                 4.761905        3.8200     9.6  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('supermarket_sales - Sheet1.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "31d88632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c4e6bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Invoice ID               1000 non-null   object \n",
      " 1   Branch                   1000 non-null   object \n",
      " 2   City                     1000 non-null   object \n",
      " 3   Customer type            1000 non-null   object \n",
      " 4   Gender                   1000 non-null   object \n",
      " 5   Product line             1000 non-null   object \n",
      " 6   Unit price               1000 non-null   float64\n",
      " 7   Quantity                 1000 non-null   int64  \n",
      " 8   Tax 5%                   1000 non-null   float64\n",
      " 9   Total                    1000 non-null   float64\n",
      " 10  Date                     1000 non-null   object \n",
      " 11  Time                     1000 non-null   object \n",
      " 12  Payment                  1000 non-null   object \n",
      " 13  cogs                     1000 non-null   float64\n",
      " 14  gross margin percentage  1000 non-null   float64\n",
      " 15  gross income             1000 non-null   float64\n",
      " 16  Rating                   1000 non-null   float64\n",
      "dtypes: float64(7), int64(1), object(9)\n",
      "memory usage: 132.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "905f7104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Invoice ID                 0\n",
       "Branch                     0\n",
       "City                       0\n",
       "Customer type              0\n",
       "Gender                     0\n",
       "Product line               0\n",
       "Unit price                 0\n",
       "Quantity                   0\n",
       "Tax 5%                     0\n",
       "Total                      0\n",
       "Date                       0\n",
       "Time                       0\n",
       "Payment                    0\n",
       "cogs                       0\n",
       "gross margin percentage    0\n",
       "gross income               0\n",
       "Rating                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b181869",
   "metadata": {},
   "source": [
    "### 1. Invoice ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "87f17477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750-67-8428    1\n",
       "642-61-4706    1\n",
       "816-72-8853    1\n",
       "491-38-3499    1\n",
       "322-02-2271    1\n",
       "              ..\n",
       "633-09-3463    1\n",
       "374-17-3652    1\n",
       "378-07-7001    1\n",
       "433-75-6987    1\n",
       "849-09-3807    1\n",
       "Name: Invoice ID, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Invoice ID'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c09371f",
   "metadata": {},
   "source": [
    "In Invoice ID column all the values are unique, so we drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "db53a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Invoice ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd6a65",
   "metadata": {},
   "source": [
    "### 2. Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c68b6e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    340\n",
       "B    332\n",
       "C    328\n",
       "Name: Branch, dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Branch'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74328dc1",
   "metadata": {},
   "source": [
    "We are use OneHotEncoder Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "16a07f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder = OneHotEncoder(dtype=int,sparse=False)\n",
    "One_hot_encoder.fit_transform(df[['Branch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f7336da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C'], dtype=object)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8203e570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(One_hot_encoder.fit_transform(df[['Branch']]))\n",
    "df1.columns= list(map(lambda x:'Branch_'+x,One_hot_encoder.categories_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "4e0d568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "cb9b42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Branch'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfad4ef",
   "metadata": {},
   "source": [
    "### 3. City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e9d9ed74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yangon       340\n",
       "Mandalay     332\n",
       "Naypyitaw    328\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "834c7d11",
   "metadata": {},
   "source": [
    "We are use OneHotEncoder Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d2cd2544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder = OneHotEncoder(dtype=int,sparse=False)\n",
    "One_hot_encoder.fit_transform(df[['City']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7a8118fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mandalay', 'Naypyitaw', 'Yangon'], dtype=object)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "732113e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(One_hot_encoder.fit_transform(df[['City']]))\n",
    "df1.columns= list(map(lambda x:'City_'+x,One_hot_encoder.categories_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "37842cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "959baa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['City'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2ac9d",
   "metadata": {},
   "source": [
    "### 4. Customer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "797f6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer type'].value_counts()\n",
    "df[\"Customer_type\"] = df['Customer type']\n",
    "df.drop(['Customer type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcda34c0",
   "metadata": {},
   "source": [
    "This column contains Ordinal data, so we use Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "69f8a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_Customer_type =  {'Normal': 0, 'Member': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6d8c6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = [{\n",
    "    'col': 'Customer_type',\n",
    "    'mapping': values_Customer_type\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b93c178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(cols=['Customer_type'], mapping=mapping)\n",
    "df['Customer_type'] = encoder.fit_transform(df['Customer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "adb111e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'Member': 1}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Customer_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d2485",
   "metadata": {},
   "source": [
    "# Unit Price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "94a88dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[[\"Unit price\"]].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "07704a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Unit_price\"] = df[\"Unit price\"]\n",
    "df.drop(columns=[\"Unit price\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4132d",
   "metadata": {},
   "source": [
    "# Tax 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f168fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tax_5\"] = df[\"Tax 5%\"]\n",
    "df.drop(columns=[\"Tax 5%\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167327e2",
   "metadata": {},
   "source": [
    "# gross income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "edc3a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gross income\"]\n",
    "df[\"gross_income\"] = df[\"gross income\"]\n",
    "df.drop(columns=[\"gross income\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb6553",
   "metadata": {},
   "source": [
    "### 5. Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "313558d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    501\n",
       "Male      499\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e08c868e",
   "metadata": {},
   "source": [
    "Gender is a ordinal data so we do label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f5c5c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['Gender'] = encoder.fit_transform(df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9ac52ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Female': 0, 'Male': 1}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Gender = dict(zip(list(encoder.classes_),list(range(len(encoder.classes_)))))\n",
    "values_Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4769a",
   "metadata": {},
   "source": [
    "### 6. Product line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "fb38119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Product line'].value_counts()\n",
    "df[\"Product_line\"] = df['Product line']\n",
    "df.drop(['Product line'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7796b3e4",
   "metadata": {},
   "source": [
    "We are use OneHotEncoder Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5cf2162e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder = OneHotEncoder(dtype=int,sparse=False)\n",
    "One_hot_encoder.fit_transform(df[['Product_line']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7ffcbe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Electronic accessories', 'Fashion accessories',\n",
       "       'Food and beverages', 'Health and beauty', 'Home and lifestyle',\n",
       "       'Sports and travel'], dtype=object)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "60c02d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(One_hot_encoder.fit_transform(df[['Product_line']]))\n",
    "df1.columns= list(map(lambda x:'Product_line_'+x,One_hot_encoder.categories_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "789a8e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0ab480af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Product_line'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392fd4e8",
   "metadata": {},
   "source": [
    "### 7. Date and Time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20b79df3",
   "metadata": {},
   "source": [
    "we are dropping Date and Time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "c4229905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Date','Time'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765aa9a3",
   "metadata": {},
   "source": [
    "### 8. Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5b484ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ewallet        345\n",
       "Cash           344\n",
       "Credit card    311\n",
       "Name: Payment, dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Payment'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5786c1dd",
   "metadata": {},
   "source": [
    "We are use OneHotEncoder Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f400d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder = OneHotEncoder(dtype=int,sparse=False)\n",
    "One_hot_encoder.fit_transform(df[['Payment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "84d47bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cash', 'Credit card', 'Ewallet'], dtype=object)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_hot_encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "dec21114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(One_hot_encoder.fit_transform(df[['Payment']]))\n",
    "df1.columns= list(map(lambda x:'Payment_'+x,One_hot_encoder.categories_[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4a010e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4bb3a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Payment'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae14b09",
   "metadata": {},
   "source": [
    "### 9. gross margin percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "eae6a6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.761905    1000\n",
       "Name: gross margin percentage, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gross margin percentage'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "782a5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['gross margin percentage'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "23444dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>...</th>\n",
       "      <th>gross_income</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>548.9715</td>\n",
       "      <td>522.83</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.2200</td>\n",
       "      <td>76.40</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>340.5255</td>\n",
       "      <td>324.31</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.2155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>489.0480</td>\n",
       "      <td>465.76</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.2880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>634.3785</td>\n",
       "      <td>604.17</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.3675</td>\n",
       "      <td>40.35</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1022.4900</td>\n",
       "      <td>973.80</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.6900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33.4320</td>\n",
       "      <td>31.84</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.1110</td>\n",
       "      <td>65.82</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>649.2990</td>\n",
       "      <td>618.38</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.9190</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Quantity      Total    cogs  Rating  Branch_A  Branch_B  \\\n",
       "0         0         7   548.9715  522.83     9.1         1         0   \n",
       "1         0         5    80.2200   76.40     9.6         0         0   \n",
       "2         1         7   340.5255  324.31     7.4         1         0   \n",
       "3         1         8   489.0480  465.76     8.4         1         0   \n",
       "4         1         7   634.3785  604.17     5.3         1         0   \n",
       "..      ...       ...        ...     ...     ...       ...       ...   \n",
       "995       1         1    42.3675   40.35     6.2         0         0   \n",
       "996       0        10  1022.4900  973.80     4.4         0         1   \n",
       "997       1         1    33.4320   31.84     7.7         1         0   \n",
       "998       1         1    69.1110   65.82     4.1         1         0   \n",
       "999       0         7   649.2990  618.38     6.6         1         0   \n",
       "\n",
       "     Branch_C  City_Mandalay  City_Naypyitaw  ...  gross_income  \\\n",
       "0           0              0               0  ...       26.1415   \n",
       "1           1              0               1  ...        3.8200   \n",
       "2           0              0               0  ...       16.2155   \n",
       "3           0              0               0  ...       23.2880   \n",
       "4           0              0               0  ...       30.2085   \n",
       "..        ...            ...             ...  ...           ...   \n",
       "995         1              0               1  ...        2.0175   \n",
       "996         0              1               0  ...       48.6900   \n",
       "997         0              0               0  ...        1.5920   \n",
       "998         0              0               0  ...        3.2910   \n",
       "999         0              0               0  ...       30.9190   \n",
       "\n",
       "     Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "0                                      0                                 0   \n",
       "1                                      1                                 0   \n",
       "2                                      0                                 0   \n",
       "3                                      0                                 0   \n",
       "4                                      0                                 0   \n",
       "..                                   ...                               ...   \n",
       "995                                    0                                 0   \n",
       "996                                    0                                 0   \n",
       "997                                    0                                 0   \n",
       "998                                    0                                 0   \n",
       "999                                    0                                 1   \n",
       "\n",
       "     Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "0                                  0                               1   \n",
       "1                                  0                               0   \n",
       "2                                  0                               0   \n",
       "3                                  0                               1   \n",
       "4                                  0                               0   \n",
       "..                               ...                             ...   \n",
       "995                                0                               1   \n",
       "996                                0                               0   \n",
       "997                                1                               0   \n",
       "998                                0                               0   \n",
       "999                                0                               0   \n",
       "\n",
       "     Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "0                                  0                               0   \n",
       "1                                  0                               0   \n",
       "2                                  1                               0   \n",
       "3                                  0                               0   \n",
       "4                                  0                               1   \n",
       "..                               ...                             ...   \n",
       "995                                0                               0   \n",
       "996                                1                               0   \n",
       "997                                0                               0   \n",
       "998                                1                               0   \n",
       "999                                0                               0   \n",
       "\n",
       "     Payment_Cash  Payment_Credit card  Payment_Ewallet  \n",
       "0               0                    0                1  \n",
       "1               1                    0                0  \n",
       "2               0                    1                0  \n",
       "3               0                    0                1  \n",
       "4               0                    0                1  \n",
       "..            ...                  ...              ...  \n",
       "995             0                    0                1  \n",
       "996             0                    0                1  \n",
       "997             1                    0                0  \n",
       "998             1                    0                0  \n",
       "999             1                    0                0  \n",
       "\n",
       "[1000 rows x 24 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "634f47ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Gender                               1000 non-null   int32  \n",
      " 1   Quantity                             1000 non-null   int64  \n",
      " 2   Total                                1000 non-null   float64\n",
      " 3   cogs                                 1000 non-null   float64\n",
      " 4   Rating                               1000 non-null   float64\n",
      " 5   Branch_A                             1000 non-null   int32  \n",
      " 6   Branch_B                             1000 non-null   int32  \n",
      " 7   Branch_C                             1000 non-null   int32  \n",
      " 8   City_Mandalay                        1000 non-null   int32  \n",
      " 9   City_Naypyitaw                       1000 non-null   int32  \n",
      " 10  City_Yangon                          1000 non-null   int32  \n",
      " 11  Customer_type                        1000 non-null   int32  \n",
      " 12  Unit_price                           1000 non-null   float64\n",
      " 13  Tax_5                                1000 non-null   float64\n",
      " 14  gross_income                         1000 non-null   float64\n",
      " 15  Product_line_Electronic accessories  1000 non-null   int32  \n",
      " 16  Product_line_Fashion accessories     1000 non-null   int32  \n",
      " 17  Product_line_Food and beverages      1000 non-null   int32  \n",
      " 18  Product_line_Health and beauty       1000 non-null   int32  \n",
      " 19  Product_line_Home and lifestyle      1000 non-null   int32  \n",
      " 20  Product_line_Sports and travel       1000 non-null   int32  \n",
      " 21  Payment_Cash                         1000 non-null   int32  \n",
      " 22  Payment_Credit card                  1000 non-null   int32  \n",
      " 23  Payment_Ewallet                      1000 non-null   int32  \n",
      "dtypes: float64(6), int32(17), int64(1)\n",
      "memory usage: 121.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "af8b7144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Quantity', 'Total', 'cogs', 'Rating', 'Branch_A', 'Branch_B',\n",
       "       'Branch_C', 'City_Mandalay', 'City_Naypyitaw', 'City_Yangon',\n",
       "       'Customer_type', 'Unit_price', 'Tax_5', 'gross_income',\n",
       "       'Product_line_Electronic accessories',\n",
       "       'Product_line_Fashion accessories', 'Product_line_Food and beverages',\n",
       "       'Product_line_Health and beauty', 'Product_line_Home and lifestyle',\n",
       "       'Product_line_Sports and travel', 'Payment_Cash', 'Payment_Credit card',\n",
       "       'Payment_Ewallet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40af5a",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e1a1396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Rating'] = df['Rating'].apply(lambda x : 1 if x > 5 else 0)\n",
    "# df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff422c7",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a12d2a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 10]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = int(df['Rating'].min())\n",
    "min_val\n",
    "\n",
    "max_val = int(df['Rating'].max())\n",
    "max_val\n",
    "\n",
    "cut_points = [5]\n",
    "\n",
    "break_points = [min_val] + cut_points + [max_val]\n",
    "break_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "3f526604",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = pd.cut(df['Rating'], bins=break_points, labels=['Not Satisfied','Satisfied'], include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "98da87a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Satisfied        826\n",
       "Not Satisfied    174\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cb99336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "df['Rating'] = encoder.fit_transform(df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "dc324742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Not Satisfied': 0, 'Satisfied': 1}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Rating = dict(zip(list(encoder.classes_),list(range(len(encoder.classes_)))))\n",
    "values_Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725fa1d",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "263f67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "aa4408e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(target_column,axis=1)\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "cd2b6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "59a46e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=5)\n",
    "x, y = sm.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "414f98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1652, 23)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "ae70a495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "38be11ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>gross_income</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75.778500</td>\n",
       "      <td>72.170000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>523.845000</td>\n",
       "      <td>498.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.945000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>530.127084</td>\n",
       "      <td>504.882937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.244147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83.474124</td>\n",
       "      <td>79.499165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.974958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>120.645000</td>\n",
       "      <td>114.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.745000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>652.890000</td>\n",
       "      <td>621.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.090000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>362.712000</td>\n",
       "      <td>345.440000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.272000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>212.782500</td>\n",
       "      <td>202.650000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.132500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>202.818000</td>\n",
       "      <td>193.160000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.658000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.986239</td>\n",
       "      <td>50.463085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.523154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Quantity       Total        cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "156        1         1   75.778500   72.170000         0         1         0   \n",
       "326        1         5  523.845000  498.900000         1         0         0   \n",
       "1519       0         7  530.127084  504.882937         0         0         0   \n",
       "1463       0         3   83.474124   79.499165         0         0         0   \n",
       "200        0         6  120.645000  114.900000         0         0         1   \n",
       "...      ...       ...         ...         ...       ...       ...       ...   \n",
       "809        0        10  652.890000  621.800000         0         0         1   \n",
       "160        0         8  362.712000  345.440000         0         0         1   \n",
       "636        1         7  212.782500  202.650000         1         0         0   \n",
       "33         1         2  202.818000  193.160000         1         0         0   \n",
       "1125       1         1   52.986239   50.463085         0         0         0   \n",
       "\n",
       "      City_Mandalay  City_Naypyitaw  City_Yangon  ...  gross_income  \\\n",
       "156               1               0            0  ...      3.608500   \n",
       "326               0               0            1  ...     24.945000   \n",
       "1519              0               0            0  ...     25.244147   \n",
       "1463              0               0            0  ...      3.974958   \n",
       "200               0               1            0  ...      5.745000   \n",
       "...             ...             ...          ...  ...           ...   \n",
       "809               0               1            0  ...     31.090000   \n",
       "160               0               1            0  ...     17.272000   \n",
       "636               0               0            1  ...     10.132500   \n",
       "33                0               0            1  ...      9.658000   \n",
       "1125              0               0            0  ...      2.523154   \n",
       "\n",
       "      Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "156                                     1                                 0   \n",
       "326                                     0                                 0   \n",
       "1519                                    0                                 0   \n",
       "1463                                    0                                 0   \n",
       "200                                     0                                 0   \n",
       "...                                   ...                               ...   \n",
       "809                                     0                                 1   \n",
       "160                                     0                                 0   \n",
       "636                                     0                                 0   \n",
       "33                                      0                                 0   \n",
       "1125                                    0                                 1   \n",
       "\n",
       "      Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "156                                 0                               0   \n",
       "326                                 1                               0   \n",
       "1519                                0                               0   \n",
       "1463                                0                               0   \n",
       "200                                 0                               0   \n",
       "...                               ...                             ...   \n",
       "809                                 0                               0   \n",
       "160                                 1                               0   \n",
       "636                                 0                               1   \n",
       "33                                  0                               1   \n",
       "1125                                0                               0   \n",
       "\n",
       "      Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "156                                 0                               0   \n",
       "326                                 0                               0   \n",
       "1519                                0                               0   \n",
       "1463                                0                               0   \n",
       "200                                 0                               1   \n",
       "...                               ...                             ...   \n",
       "809                                 0                               0   \n",
       "160                                 0                               0   \n",
       "636                                 0                               0   \n",
       "33                                  0                               0   \n",
       "1125                                0                               0   \n",
       "\n",
       "      Payment_Cash  Payment_Credit card  Payment_Ewallet  \n",
       "156              1                    0                0  \n",
       "326              1                    0                0  \n",
       "1519             0                    0                0  \n",
       "1463             0                    1                0  \n",
       "200              0                    1                0  \n",
       "...            ...                  ...              ...  \n",
       "809              0                    0                1  \n",
       "160              0                    1                0  \n",
       "636              0                    1                0  \n",
       "33               0                    1                0  \n",
       "1125             0                    0                0  \n",
       "\n",
       "[1156 rows x 23 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de0844",
   "metadata": {},
   "source": [
    "#  Outlier Handeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "62c7028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "x.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97626632",
   "metadata": {},
   "source": [
    "### Tax 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e128dc7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Tax_5'>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x['Tax_5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69a3bb",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ee991181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Total'>"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x['Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9879204",
   "metadata": {},
   "source": [
    "### cogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "df64e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='cogs'>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x['cogs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabeb580",
   "metadata": {},
   "source": [
    "### gross income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9cc7ff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='gross_income'>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x['gross_income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "42993730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Instance\n",
    "# preprocessing = DataPreProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "91fa7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = preprocessing.replace_outliers_by_nan(x,outlier_columns=['Tax 5%','Total','cogs','gross income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "11f66736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "x.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f1f4f371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = preprocessing.knn_imputer(x,continuous_columns = ['Tax 5%','Total','cogs','gross income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "80549af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13519a",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9c00843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>gross_income</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>548.9715</td>\n",
       "      <td>522.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.2200</td>\n",
       "      <td>76.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Quantity     Total    cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "0       0         7  548.9715  522.83         1         0         0   \n",
       "1       0         5   80.2200   76.40         0         0         1   \n",
       "\n",
       "   City_Mandalay  City_Naypyitaw  City_Yangon  ...  gross_income  \\\n",
       "0              0               0            1  ...       26.1415   \n",
       "1              0               1            0  ...        3.8200   \n",
       "\n",
       "   Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "0                                    0                                 0   \n",
       "1                                    1                                 0   \n",
       "\n",
       "   Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "0                                0                               1   \n",
       "1                                0                               0   \n",
       "\n",
       "   Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "0                                0                               0   \n",
       "1                                0                               0   \n",
       "\n",
       "   Payment_Cash  Payment_Credit card  Payment_Ewallet  \n",
       "0             0                    0                1  \n",
       "1             1                    0                0  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a3bd0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = ['Unit_price','Tax_5','Total','cogs','gross_income']\n",
    "catogorical_columns = ['Customer_type', 'Gender','Quantity', 'Branch_A', 'Branch_B', 'Branch_C',\n",
    "       'City_Mandalay', 'City_Naypyitaw', 'City_Yangon',\n",
    "       'Product_line_Electronic accessories',\n",
    "       'Product_line_Fashion accessories', 'Product_line_Food and beverages',\n",
    "       'Product_line_Health and beauty', 'Product_line_Home and lifestyle',\n",
    "       'Product_line_Sports and travel', 'Payment_Cash', 'Payment_Credit card',\n",
    "       'Payment_Ewallet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479605c8",
   "metadata": {},
   "source": [
    "### 0. correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "818c05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>0.26241</td>\n",
       "      <td>0.05163</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.22449</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.22449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17686</td>\n",
       "      <td>0.159738</td>\n",
       "      <td>0.202049</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.133428</td>\n",
       "      <td>0.209023</td>\n",
       "      <td>0.194734</td>\n",
       "      <td>0.178355</td>\n",
       "      <td>0.194956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gender  Quantity    Total     cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "Rating  0.26241   0.05163  0.00025  0.00025   0.22449  0.160249  0.263952   \n",
       "\n",
       "        City_Mandalay  City_Naypyitaw  City_Yangon  ...  \\\n",
       "Rating       0.160249        0.263952      0.22449  ...   \n",
       "\n",
       "        Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "Rating                              0.17686                          0.159738   \n",
       "\n",
       "        Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "Rating                         0.202049                        0.156215   \n",
       "\n",
       "        Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "Rating                         0.133428                        0.209023   \n",
       "\n",
       "        Payment_Cash  Payment_Credit card  Payment_Ewallet  Rating  \n",
       "Rating      0.194734             0.178355         0.194956     1.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.concat([x,y],axis=1).corr('kendall').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "c287834f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <td>0.26241</td>\n",
       "      <td>0.060243</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.22449</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.160249</td>\n",
       "      <td>0.263952</td>\n",
       "      <td>0.22449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17686</td>\n",
       "      <td>0.159738</td>\n",
       "      <td>0.202049</td>\n",
       "      <td>0.156215</td>\n",
       "      <td>0.133428</td>\n",
       "      <td>0.209023</td>\n",
       "      <td>0.194734</td>\n",
       "      <td>0.178355</td>\n",
       "      <td>0.194956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gender  Quantity     Total      cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "Rating  0.26241  0.060243  0.000306  0.000306   0.22449  0.160249  0.263952   \n",
       "\n",
       "        City_Mandalay  City_Naypyitaw  City_Yangon  ...  \\\n",
       "Rating       0.160249        0.263952      0.22449  ...   \n",
       "\n",
       "        Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "Rating                              0.17686                          0.159738   \n",
       "\n",
       "        Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "Rating                         0.202049                        0.156215   \n",
       "\n",
       "        Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "Rating                         0.133428                        0.209023   \n",
       "\n",
       "        Payment_Cash  Payment_Credit card  Payment_Ewallet  Rating  \n",
       "Rating      0.194734             0.178355         0.194956     1.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.concat([x,y],axis=1).corr('spearman').tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089edd31",
   "metadata": {},
   "source": [
    "### 1. chi-square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "fed4e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "cc49d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistics, p_value = chi2(x[catogorical_columns],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "1b0f2111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_type                          7.697257e-04\n",
       "Gender                                 6.265216e-17\n",
       "Quantity                               1.585275e-03\n",
       "Branch_A                               2.020491e-15\n",
       "Branch_B                               1.785721e-08\n",
       "Branch_C                               4.301896e-21\n",
       "City_Mandalay                          1.785721e-08\n",
       "City_Naypyitaw                         4.301896e-21\n",
       "City_Yangon                            2.020491e-15\n",
       "Product_line_Electronic accessories    1.335353e-11\n",
       "Product_line_Fashion accessories       1.229538e-09\n",
       "Product_line_Food and beverages        1.068354e-14\n",
       "Product_line_Health and beauty         1.767700e-09\n",
       "Product_line_Home and lifestyle        3.303143e-07\n",
       "Product_line_Sports and travel         9.294052e-16\n",
       "Payment_Cash                           1.160685e-11\n",
       "Payment_Credit card                    2.003586e-10\n",
       "Payment_Ewallet                        8.886839e-12\n",
       "dtype: float64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(p_value, index=catogorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5281e",
   "metadata": {},
   "source": [
    "## 2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "75855b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "dc876669",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistics, p_value = f_classif(x[continuous_columns],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "00dac09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unit_price      0.548122\n",
       "Tax_5           0.232295\n",
       "Total           0.232295\n",
       "cogs            0.232295\n",
       "gross_income    0.232295\n",
       "dtype: float64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(p_value, index=continuous_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb3d4b5",
   "metadata": {},
   "source": [
    "### 3. Mutual information (Information Gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a9a4800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b6c0f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = mutual_info_classif(x,y,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "c34543cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s2 = pd.Series(array, index=x.columns)\n",
    "s2.sort_values().plot(kind= 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c300cc87",
   "metadata": {},
   "source": [
    "### 2.1 . Exhaustive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6262e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2c5eb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "7d924fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 10626/10626"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExhaustiveFeatureSelector(estimator=DecisionTreeClassifier(),\n",
       "                          feature_groups=[[0], [1], [2], [3], [4], [5], [6],\n",
       "                                          [7], [8], [9], [10], [11], [12], [13],\n",
       "                                          [14], [15], [16], [17], [18], [19],\n",
       "                                          [20], [21], [22]],\n",
       "                          max_features=20, min_features=19, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExhaustiveFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>ExhaustiveFeatureSelector(estimator=DecisionTreeClassifier(),\n",
       "                          feature_groups=[[0], [1], [2], [3], [4], [5], [6],\n",
       "                                          [7], [8], [9], [10], [11], [12], [13],\n",
       "                                          [14], [15], [16], [17], [18], [19],\n",
       "                                          [20], [21], [22]],\n",
       "                          max_features=20, min_features=19, n_jobs=-1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExhaustiveFeatureSelector(estimator=DecisionTreeClassifier(),\n",
       "                          feature_groups=[[0], [1], [2], [3], [4], [5], [6],\n",
       "                                          [7], [8], [9], [10], [11], [12], [13],\n",
       "                                          [14], [15], [16], [17], [18], [19],\n",
       "                                          [20], [21], [22]],\n",
       "                          max_features=20, min_features=19, n_jobs=-1)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs = ExhaustiveFeatureSelector(DecisionTreeClassifier(), min_features=19, max_features=20, cv=5, n_jobs=-1)\n",
    "efs.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "afaf3043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.6102719033232629, 0.8549848942598187, 0.842...</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>(Gender, Quantity, Total, cogs, Branch_A, Bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.595166163141994, 0.8580060422960725, 0.8727...</td>\n",
       "      <td>0.811241</td>\n",
       "      <td>(Gender, Quantity, Total, cogs, Branch_A, Bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.5891238670694864, 0.8368580060422961, 0.884...</td>\n",
       "      <td>0.800954</td>\n",
       "      <td>(Gender, Quantity, Total, cogs, Branch_A, Bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.5891238670694864, 0.8429003021148036, 0.845...</td>\n",
       "      <td>0.798526</td>\n",
       "      <td>(Gender, Quantity, Total, cogs, Branch_A, Bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[0.6163141993957704, 0.8731117824773413, 0.860...</td>\n",
       "      <td>0.813037</td>\n",
       "      <td>(Gender, Quantity, Total, cogs, Branch_A, Bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10621</th>\n",
       "      <td>(2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.5800604229607251, 0.8459214501510574, 0.860...</td>\n",
       "      <td>0.807015</td>\n",
       "      <td>(Total, cogs, Branch_A, Branch_B, City_Mandala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>(2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.5740181268882175, 0.8459214501510574, 0.857...</td>\n",
       "      <td>0.803988</td>\n",
       "      <td>(Total, cogs, Branch_A, Branch_C, City_Mandala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>(2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.5770392749244713, 0.8459214501510574, 0.857...</td>\n",
       "      <td>0.80338</td>\n",
       "      <td>(Total, cogs, Branch_B, Branch_C, City_Mandala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>(2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.5770392749244713, 0.851963746223565, 0.8666...</td>\n",
       "      <td>0.805801</td>\n",
       "      <td>(Total, Branch_A, Branch_B, Branch_C, City_Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>(3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[0.5770392749244713, 0.8489425981873112, 0.860...</td>\n",
       "      <td>0.807621</td>\n",
       "      <td>(cogs, Branch_A, Branch_B, Branch_C, City_Mand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10626 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature_idx  \\\n",
       "0      (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1      (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2      (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3      (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4      (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "...                                                  ...   \n",
       "10621  (2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "10622  (2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "10623  (2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "10624  (2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "10625  (3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "\n",
       "                                               cv_scores avg_score  \\\n",
       "0      [0.6102719033232629, 0.8549848942598187, 0.842...  0.808809   \n",
       "1      [0.595166163141994, 0.8580060422960725, 0.8727...  0.811241   \n",
       "2      [0.5891238670694864, 0.8368580060422961, 0.884...  0.800954   \n",
       "3      [0.5891238670694864, 0.8429003021148036, 0.845...  0.798526   \n",
       "4      [0.6163141993957704, 0.8731117824773413, 0.860...  0.813037   \n",
       "...                                                  ...       ...   \n",
       "10621  [0.5800604229607251, 0.8459214501510574, 0.860...  0.807015   \n",
       "10622  [0.5740181268882175, 0.8459214501510574, 0.857...  0.803988   \n",
       "10623  [0.5770392749244713, 0.8459214501510574, 0.857...   0.80338   \n",
       "10624  [0.5770392749244713, 0.851963746223565, 0.8666...  0.805801   \n",
       "10625  [0.5770392749244713, 0.8489425981873112, 0.860...  0.807621   \n",
       "\n",
       "                                           feature_names  \n",
       "0      (Gender, Quantity, Total, cogs, Branch_A, Bran...  \n",
       "1      (Gender, Quantity, Total, cogs, Branch_A, Bran...  \n",
       "2      (Gender, Quantity, Total, cogs, Branch_A, Bran...  \n",
       "3      (Gender, Quantity, Total, cogs, Branch_A, Bran...  \n",
       "4      (Gender, Quantity, Total, cogs, Branch_A, Bran...  \n",
       "...                                                  ...  \n",
       "10621  (Total, cogs, Branch_A, Branch_B, City_Mandala...  \n",
       "10622  (Total, cogs, Branch_A, Branch_C, City_Mandala...  \n",
       "10623  (Total, cogs, Branch_B, Branch_C, City_Mandala...  \n",
       "10624  (Total, Branch_A, Branch_B, Branch_C, City_Man...  \n",
       "10625  (cogs, Branch_A, Branch_B, Branch_C, City_Mand...  \n",
       "\n",
       "[10626 rows x 4 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(efs.subsets_).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4791a8",
   "metadata": {},
   "source": [
    "### 2.2 Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "87c6996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# rfe = RFE(dt_model, n_features_to_select=15)\n",
    "# rfe.fit(x,y)\n",
    "# x = x[rfe.get_feature_names_out()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d4593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "721517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "5805d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Rating\"\n",
    "# x = df.drop(target_column,axis=1)\n",
    "# y = df[target_column]\n",
    "\n",
    "# # Create an instance\n",
    "# smote = SMOTE(random_state=None, k_neighbors = 5, sampling_strategy=0.9)\n",
    "\n",
    "# x , y = smote.fit_resample(x,y)  # 50:50\n",
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "dd92e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_column = \"Rating\"\n",
    "# x = df.drop(target_column,axis=1)\n",
    "# y = df[target_column]\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "9c44c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8cad4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['Unit price','Quantity','Tax 5%','Total','cogs','gross income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ce4b1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "77c35d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>548.971500</td>\n",
       "      <td>522.830000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.220000</td>\n",
       "      <td>76.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>340.525500</td>\n",
       "      <td>324.310000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>489.048000</td>\n",
       "      <td>465.760000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>634.378500</td>\n",
       "      <td>604.170000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>404.908990</td>\n",
       "      <td>385.627609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.518652</td>\n",
       "      <td>50.017764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>99.362260</td>\n",
       "      <td>94.630724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>808.622281</td>\n",
       "      <td>770.116458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>227.969918</td>\n",
       "      <td>217.114208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1652 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Quantity       Total        cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "0          0         7  548.971500  522.830000         1         0         0   \n",
       "1          0         5   80.220000   76.400000         0         0         1   \n",
       "2          1         7  340.525500  324.310000         1         0         0   \n",
       "3          1         8  489.048000  465.760000         1         0         0   \n",
       "4          1         7  634.378500  604.170000         1         0         0   \n",
       "...      ...       ...         ...         ...       ...       ...       ...   \n",
       "1647       0         4  404.908990  385.627609         0         0         0   \n",
       "1648       1         1   52.518652   50.017764         0         0         0   \n",
       "1649       0         4   99.362260   94.630724         0         1         0   \n",
       "1650       0         8  808.622281  770.116458         0         0         0   \n",
       "1651       0         8  227.969918  217.114208         0         0         0   \n",
       "\n",
       "      City_Mandalay  City_Naypyitaw  City_Yangon  ...  \\\n",
       "0                 0               0            1  ...   \n",
       "1                 0               1            0  ...   \n",
       "2                 0               0            1  ...   \n",
       "3                 0               0            1  ...   \n",
       "4                 0               0            1  ...   \n",
       "...             ...             ...          ...  ...   \n",
       "1647              0               0            0  ...   \n",
       "1648              0               0            0  ...   \n",
       "1649              1               0            0  ...   \n",
       "1650              0               0            0  ...   \n",
       "1651              0               0            0  ...   \n",
       "\n",
       "      Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "0                                       0                                 0   \n",
       "1                                       1                                 0   \n",
       "2                                       0                                 0   \n",
       "3                                       0                                 0   \n",
       "4                                       0                                 0   \n",
       "...                                   ...                               ...   \n",
       "1647                                    0                                 0   \n",
       "1648                                    0                                 0   \n",
       "1649                                    0                                 0   \n",
       "1650                                    0                                 0   \n",
       "1651                                    0                                 0   \n",
       "\n",
       "      Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "0                                   0                               1   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               1   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "1647                                0                               0   \n",
       "1648                                0                               0   \n",
       "1649                                0                               0   \n",
       "1650                                0                               0   \n",
       "1651                                0                               0   \n",
       "\n",
       "      Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   1                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               1   \n",
       "...                               ...                             ...   \n",
       "1647                                0                               0   \n",
       "1648                                0                               0   \n",
       "1649                                0                               0   \n",
       "1650                                0                               0   \n",
       "1651                                0                               0   \n",
       "\n",
       "      Payment_Cash  Payment_Credit card  Payment_Ewallet  Rating  \n",
       "0                0                    0                1       1  \n",
       "1                1                    0                0       1  \n",
       "2                0                    1                0       1  \n",
       "3                0                    0                1       1  \n",
       "4                0                    0                1       1  \n",
       "...            ...                  ...              ...     ...  \n",
       "1647             0                    0                1       0  \n",
       "1648             0                    0                0       0  \n",
       "1649             0                    0                0       0  \n",
       "1650             0                    0                0       0  \n",
       "1651             1                    0                0       0  \n",
       "\n",
       "[1652 rows x 24 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([x,y],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "70baf4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def svm_std_scalar(df):\n",
    "#     df1 = df.copy()\n",
    "    \n",
    "#     x1 = ['Unit price','Quantity','Tax 5%','Total','cogs','gross income']\n",
    "    \n",
    "#     std_scalar = StandardScaler()\n",
    "#     std_scalar.fit(df1[x1])\n",
    "#     array = std_scalar.transform(df1[x1])\n",
    "#     x = pd.DataFrame(array, columns=x1)\n",
    "#     for i in x1:\n",
    "#         df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "#     target_column = \"Rating\"\n",
    "#     x = df1.drop(target_column,axis=1)\n",
    "#     y = df1[target_column]\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "#     svm_std=SVC()\n",
    "#     svm_std.fit(x_train,y_train)\n",
    "#     model_details.append(\"SVM with Std Scaling\")\n",
    "#     #Testing Data\n",
    "#     y_pred = svm_std.predict(x_test)\n",
    "#     cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "#     print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "#     accuracy = accuracy_score(y_pred, y_test)*100\n",
    "#     print(\"Accuracy Score\", accuracy)\n",
    "#     Testing_accuracy.append(accuracy)\n",
    "#     clf_report = classification_report(y_pred, y_test)\n",
    "#     print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "#     recall = recall_score(y_pred,y_test)*100\n",
    "#     print(\"Recall :\" ,recall)\n",
    "#     Testing_Recall.append(recall)\n",
    "    \n",
    "#     precision = precision_score(y_pred,y_test)*100\n",
    "#     print(\"Precision :\",precision)\n",
    "#     Testing_Precision.append(precision)\n",
    "    \n",
    "#     F1_score = f1_score(y_pred,y_test)*100\n",
    "#     print(\"F1-Score :\",F1_score)\n",
    "#     Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "#     print(\"@\"*120)\n",
    "#     #Training Data\n",
    "#     y_pred_train = svm_std.predict(x_train)\n",
    "#     cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "#     print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "#     accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "#     print(\"Accuracy Score\", accuracy)\n",
    "#     Training_accuracy.append(accuracy)\n",
    "#     clf_report = classification_report(y_pred_train, y_train)\n",
    "#     print(\"Classification report:\\n\",clf_report) \n",
    "# #     print(x_train)\n",
    "# svm_std_scalar(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "22b56ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>cogs</th>\n",
       "      <th>Branch_A</th>\n",
       "      <th>Branch_B</th>\n",
       "      <th>Branch_C</th>\n",
       "      <th>City_Mandalay</th>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <th>City_Yangon</th>\n",
       "      <th>...</th>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <th>Payment_Cash</th>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <th>Payment_Ewallet</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>548.971500</td>\n",
       "      <td>522.830000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>80.220000</td>\n",
       "      <td>76.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>340.525500</td>\n",
       "      <td>324.310000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>489.048000</td>\n",
       "      <td>465.760000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>634.378500</td>\n",
       "      <td>604.170000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>404.908990</td>\n",
       "      <td>385.627609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.518652</td>\n",
       "      <td>50.017764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>99.362260</td>\n",
       "      <td>94.630724</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>808.622281</td>\n",
       "      <td>770.116458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>227.969918</td>\n",
       "      <td>217.114208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1652 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Quantity       Total        cogs  Branch_A  Branch_B  Branch_C  \\\n",
       "0          0         7  548.971500  522.830000         1         0         0   \n",
       "1          0         5   80.220000   76.400000         0         0         1   \n",
       "2          1         7  340.525500  324.310000         1         0         0   \n",
       "3          1         8  489.048000  465.760000         1         0         0   \n",
       "4          1         7  634.378500  604.170000         1         0         0   \n",
       "...      ...       ...         ...         ...       ...       ...       ...   \n",
       "1647       0         4  404.908990  385.627609         0         0         0   \n",
       "1648       1         1   52.518652   50.017764         0         0         0   \n",
       "1649       0         4   99.362260   94.630724         0         1         0   \n",
       "1650       0         8  808.622281  770.116458         0         0         0   \n",
       "1651       0         8  227.969918  217.114208         0         0         0   \n",
       "\n",
       "      City_Mandalay  City_Naypyitaw  City_Yangon  ...  \\\n",
       "0                 0               0            1  ...   \n",
       "1                 0               1            0  ...   \n",
       "2                 0               0            1  ...   \n",
       "3                 0               0            1  ...   \n",
       "4                 0               0            1  ...   \n",
       "...             ...             ...          ...  ...   \n",
       "1647              0               0            0  ...   \n",
       "1648              0               0            0  ...   \n",
       "1649              1               0            0  ...   \n",
       "1650              0               0            0  ...   \n",
       "1651              0               0            0  ...   \n",
       "\n",
       "      Product_line_Electronic accessories  Product_line_Fashion accessories  \\\n",
       "0                                       0                                 0   \n",
       "1                                       1                                 0   \n",
       "2                                       0                                 0   \n",
       "3                                       0                                 0   \n",
       "4                                       0                                 0   \n",
       "...                                   ...                               ...   \n",
       "1647                                    0                                 0   \n",
       "1648                                    0                                 0   \n",
       "1649                                    0                                 0   \n",
       "1650                                    0                                 0   \n",
       "1651                                    0                                 0   \n",
       "\n",
       "      Product_line_Food and beverages  Product_line_Health and beauty  \\\n",
       "0                                   0                               1   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               1   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "1647                                0                               0   \n",
       "1648                                0                               0   \n",
       "1649                                0                               0   \n",
       "1650                                0                               0   \n",
       "1651                                0                               0   \n",
       "\n",
       "      Product_line_Home and lifestyle  Product_line_Sports and travel  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   1                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               1   \n",
       "...                               ...                             ...   \n",
       "1647                                0                               0   \n",
       "1648                                0                               0   \n",
       "1649                                0                               0   \n",
       "1650                                0                               0   \n",
       "1651                                0                               0   \n",
       "\n",
       "      Payment_Cash  Payment_Credit card  Payment_Ewallet  Rating  \n",
       "0                0                    0                1       1  \n",
       "1                1                    0                0       1  \n",
       "2                0                    1                0       1  \n",
       "3                0                    0                1       1  \n",
       "4                0                    0                1       1  \n",
       "...            ...                  ...              ...     ...  \n",
       "1647             0                    0                1       0  \n",
       "1648             0                    0                0       0  \n",
       "1649             0                    0                0       0  \n",
       "1650             0                    0                0       0  \n",
       "1651             1                    0                0       0  \n",
       "\n",
       "[1652 rows x 24 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b01c04",
   "metadata": {},
   "source": [
    "# Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "75aad9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ SVM Classification *********************************************\n",
      "Confusion Matrix:\n",
      " [[156 122]\n",
      " [ 92 126]]\n",
      "*******************************************************\n",
      "Accuracy Score: 56.85483870967742\n",
      "*******************************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59       278\n",
      "           1       0.51      0.58      0.54       218\n",
      "\n",
      "    accuracy                           0.57       496\n",
      "   macro avg       0.57      0.57      0.57       496\n",
      "weighted avg       0.58      0.57      0.57       496\n",
      "\n",
      "Recall : 57.798165137614674\n",
      "Precision : 50.806451612903224\n",
      "F1-Score : 54.07725321888412\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[332 265]\n",
      " [246 313]]\n",
      "*******************************************************\n",
      "Accuracy Score: 55.79584775086506\n",
      "*******************************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.56      0.57       597\n",
      "           1       0.54      0.56      0.55       559\n",
      "\n",
      "    accuracy                           0.56      1156\n",
      "   macro avg       0.56      0.56      0.56      1156\n",
      "weighted avg       0.56      0.56      0.56      1156\n",
      "\n",
      "************************************ SVM with Hyperparameter  *********************************************\n",
      "Confusion Matrix:\n",
      " [[196   0]\n",
      " [ 52 248]]\n",
      "*******************************************************\n",
      "Accuracy Score: 89.51612903225806\n",
      "*******************************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       196\n",
      "           1       1.00      0.83      0.91       300\n",
      "\n",
      "    accuracy                           0.90       496\n",
      "   macro avg       0.90      0.91      0.89       496\n",
      "weighted avg       0.92      0.90      0.90       496\n",
      "\n",
      "Recall : 82.66666666666667\n",
      "Precision : 100.0\n",
      "F1-Score : 90.51094890510949\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[442   0]\n",
      " [136 578]]\n",
      "*******************************************************\n",
      "Accuracy Score: 88.23529411764706\n",
      "*******************************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87       442\n",
      "           1       1.00      0.81      0.89       714\n",
      "\n",
      "    accuracy                           0.88      1156\n",
      "   macro avg       0.88      0.90      0.88      1156\n",
      "weighted avg       0.91      0.88      0.88      1156\n",
      "\n",
      "************************************ SVM with Standard scalar*********************************************\n",
      "Confusion Matrix:\n",
      " [[191   2]\n",
      " [ 57 246]]\n",
      "Accuracy Score 88.10483870967742\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       193\n",
      "           1       0.99      0.81      0.89       303\n",
      "\n",
      "    accuracy                           0.88       496\n",
      "   macro avg       0.88      0.90      0.88       496\n",
      "weighted avg       0.91      0.88      0.88       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 81.1881188118812\n",
      "Precision : 99.19354838709677\n",
      "F1-Score : 89.29219600725953\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[435   1]\n",
      " [143 577]]\n",
      "Accuracy Score 87.5432525951557\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       436\n",
      "           1       1.00      0.80      0.89       720\n",
      "\n",
      "    accuracy                           0.88      1156\n",
      "   macro avg       0.88      0.90      0.87      1156\n",
      "weighted avg       0.91      0.88      0.88      1156\n",
      "\n",
      "************************************ SVM with normal scalar*********************************************\n",
      "Confusion Matrix:\n",
      " [[198   2]\n",
      " [ 50 246]]\n",
      "Accuracy Score 89.51612903225806\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       200\n",
      "           1       0.99      0.83      0.90       296\n",
      "\n",
      "    accuracy                           0.90       496\n",
      "   macro avg       0.90      0.91      0.89       496\n",
      "weighted avg       0.91      0.90      0.90       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 83.1081081081081\n",
      "Precision : 99.19354838709677\n",
      "F1-Score : 90.44117647058823\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[446   0]\n",
      " [132 578]]\n",
      "Accuracy Score 88.58131487889274\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       446\n",
      "           1       1.00      0.81      0.90       710\n",
      "\n",
      "    accuracy                           0.89      1156\n",
      "   macro avg       0.89      0.91      0.88      1156\n",
      "weighted avg       0.91      0.89      0.89      1156\n",
      "\n",
      "************************************ Logistic Regression*********************************************\n",
      "Confusion Matrix:\n",
      " [[184   0]\n",
      " [ 64 248]]\n",
      "Accuracy Score 87.09677419354838\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       184\n",
      "           1       1.00      0.79      0.89       312\n",
      "\n",
      "    accuracy                           0.87       496\n",
      "   macro avg       0.87      0.90      0.87       496\n",
      "weighted avg       0.90      0.87      0.87       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 79.48717948717949\n",
      "Precision : 100.0\n",
      "F1-Score : 88.57142857142858\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[435   0]\n",
      " [143 578]]\n",
      "Accuracy Score 87.62975778546713\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       435\n",
      "           1       1.00      0.80      0.89       721\n",
      "\n",
      "    accuracy                           0.88      1156\n",
      "   macro avg       0.88      0.90      0.87      1156\n",
      "weighted avg       0.91      0.88      0.88      1156\n",
      "\n",
      "************************************ K-Neighbours Regression*********************************************\n",
      "Confusion Matrix:\n",
      " [[187 104]\n",
      " [ 61 144]]\n",
      "Accuracy Score 66.73387096774194\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       291\n",
      "           1       0.58      0.70      0.64       205\n",
      "\n",
      "    accuracy                           0.67       496\n",
      "   macro avg       0.67      0.67      0.66       496\n",
      "weighted avg       0.68      0.67      0.67       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 70.24390243902438\n",
      "Precision : 58.06451612903226\n",
      "F1-Score : 63.576158940397356\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[483 162]\n",
      " [ 95 416]]\n",
      "Accuracy Score 77.76816608996539\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79       645\n",
      "           1       0.72      0.81      0.76       511\n",
      "\n",
      "    accuracy                           0.78      1156\n",
      "   macro avg       0.78      0.78      0.78      1156\n",
      "weighted avg       0.78      0.78      0.78      1156\n",
      "\n",
      "************************************ K-Neighbours with std scalar *********************************************\n",
      "Confusion Matrix:\n",
      " [[221  70]\n",
      " [ 27 178]]\n",
      "Accuracy Score 80.44354838709677\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82       291\n",
      "           1       0.72      0.87      0.79       205\n",
      "\n",
      "    accuracy                           0.80       496\n",
      "   macro avg       0.80      0.81      0.80       496\n",
      "weighted avg       0.82      0.80      0.81       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 86.82926829268293\n",
      "Precision : 71.7741935483871\n",
      "F1-Score : 78.58719646799118\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[523  73]\n",
      " [ 55 505]]\n",
      "Accuracy Score 88.92733564013841\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       596\n",
      "           1       0.87      0.90      0.89       560\n",
      "\n",
      "    accuracy                           0.89      1156\n",
      "   macro avg       0.89      0.89      0.89      1156\n",
      "weighted avg       0.89      0.89      0.89      1156\n",
      "\n",
      "************************************ K-Neighbours with normal scalar*********************************************\n",
      "Confusion Matrix:\n",
      " [[213  41]\n",
      " [ 35 207]]\n",
      "Accuracy Score 84.67741935483872\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       254\n",
      "           1       0.83      0.86      0.84       242\n",
      "\n",
      "    accuracy                           0.85       496\n",
      "   macro avg       0.85      0.85      0.85       496\n",
      "weighted avg       0.85      0.85      0.85       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 85.53719008264463\n",
      "Precision : 83.46774193548387\n",
      "F1-Score : 84.48979591836734\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[498  33]\n",
      " [ 80 545]]\n",
      "Accuracy Score 90.22491349480968\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       531\n",
      "           1       0.94      0.87      0.91       625\n",
      "\n",
      "    accuracy                           0.90      1156\n",
      "   macro avg       0.90      0.90      0.90      1156\n",
      "weighted avg       0.91      0.90      0.90      1156\n",
      "\n",
      "************************************** KNN-HyperParameter Tuning  **********************************************\n",
      "Confusion Matrix:\n",
      " [[222  68]\n",
      " [ 26 180]]\n",
      "Accuracy Score 81.04838709677419\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.77      0.83       290\n",
      "           1       0.73      0.87      0.79       206\n",
      "\n",
      "    accuracy                           0.81       496\n",
      "   macro avg       0.81      0.82      0.81       496\n",
      "weighted avg       0.82      0.81      0.81       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 87.37864077669903\n",
      "Precision : 72.58064516129032\n",
      "F1-Score : 79.29515418502203\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[526  52]\n",
      " [ 52 526]]\n",
      "Accuracy Score 91.00346020761245\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       578\n",
      "           1       0.91      0.91      0.91       578\n",
      "\n",
      "    accuracy                           0.91      1156\n",
      "   macro avg       0.91      0.91      0.91      1156\n",
      "weighted avg       0.91      0.91      0.91      1156\n",
      "\n",
      "************************************ Decision-Tree Regression*********************************************\n",
      "Confusion Matrix:\n",
      " [[212  67]\n",
      " [ 36 181]]\n",
      "Accuracy Score 79.23387096774194\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80       279\n",
      "           1       0.73      0.83      0.78       217\n",
      "\n",
      "    accuracy                           0.79       496\n",
      "   macro avg       0.79      0.80      0.79       496\n",
      "weighted avg       0.80      0.79      0.79       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 83.41013824884793\n",
      "Precision : 72.98387096774194\n",
      "F1-Score : 77.84946236559142\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[578   0]\n",
      " [  0 578]]\n",
      "Accuracy Score 100.0\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       578\n",
      "           1       1.00      1.00      1.00       578\n",
      "\n",
      "    accuracy                           1.00      1156\n",
      "   macro avg       1.00      1.00      1.00      1156\n",
      "weighted avg       1.00      1.00      1.00      1156\n",
      "\n",
      "************************************** Pre_prunning Decision Tree  **********************************************\n",
      "Confusion Matrix:\n",
      " [[191  57]\n",
      " [ 57 191]]\n",
      "*********************************************\n",
      "Accuracy Score: 77.01612903225806\n",
      "*********************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       248\n",
      "           1       0.77      0.77      0.77       248\n",
      "\n",
      "    accuracy                           0.77       496\n",
      "   macro avg       0.77      0.77      0.77       496\n",
      "weighted avg       0.77      0.77      0.77       496\n",
      "\n",
      "Recall : 77.01612903225806\n",
      "Precision : 77.01612903225806\n",
      "F1-Score : 77.01612903225806\n",
      "******************************************************************************************\n",
      "Confusion Matrix:\n",
      " [[448 130]\n",
      " [ 91 487]]\n",
      "*********************************************\n",
      "Accuracy Score: 80.88235294117648\n",
      "*********************************************\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80       578\n",
      "           1       0.79      0.84      0.82       578\n",
      "\n",
      "    accuracy                           0.81      1156\n",
      "   macro avg       0.81      0.81      0.81      1156\n",
      "weighted avg       0.81      0.81      0.81      1156\n",
      "\n",
      "**************************************  Post Pruning-CCP Alpha DT **********************************************\n",
      "Confusion Matrix:\n",
      " [[197  28]\n",
      " [ 51 220]]\n",
      "Accuracy Score 84.07258064516128\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       225\n",
      "           1       0.89      0.81      0.85       271\n",
      "\n",
      "    accuracy                           0.84       496\n",
      "   macro avg       0.84      0.84      0.84       496\n",
      "weighted avg       0.85      0.84      0.84       496\n",
      "\n",
      "Recall : 81.18081180811808\n",
      "Precision : 88.70967741935483\n",
      "F1-Score : 84.77842003853564\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[476  23]\n",
      " [102 555]]\n",
      "Accuracy Score 89.18685121107266\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       499\n",
      "           1       0.96      0.84      0.90       657\n",
      "\n",
      "    accuracy                           0.89      1156\n",
      "   macro avg       0.89      0.90      0.89      1156\n",
      "weighted avg       0.90      0.89      0.89      1156\n",
      "\n",
      "************************************ Random- Forest  Regression*********************************************\n",
      "Confusion Matrix:\n",
      " [[210  25]\n",
      " [ 38 223]]\n",
      "Accuracy Score 87.29838709677419\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       235\n",
      "           1       0.90      0.85      0.88       261\n",
      "\n",
      "    accuracy                           0.87       496\n",
      "   macro avg       0.87      0.87      0.87       496\n",
      "weighted avg       0.87      0.87      0.87       496\n",
      "\n",
      "Recall : 85.44061302681992\n",
      "Precision : 89.91935483870968\n",
      "F1-Score : 87.62278978388998\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[578   0]\n",
      " [  0 578]]\n",
      "Accuracy Score 100.0\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       578\n",
      "           1       1.00      1.00      1.00       578\n",
      "\n",
      "    accuracy                           1.00      1156\n",
      "   macro avg       1.00      1.00      1.00      1156\n",
      "weighted avg       1.00      1.00      1.00      1156\n",
      "\n",
      "**************************************  Hyper-parameter Random-Forest **********************************************\n",
      "Confusion Matrix:\n",
      " [[185  34]\n",
      " [ 63 214]]\n",
      "Accuracy Score 80.44354838709677\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       219\n",
      "           1       0.86      0.77      0.82       277\n",
      "\n",
      "    accuracy                           0.80       496\n",
      "   macro avg       0.80      0.81      0.80       496\n",
      "weighted avg       0.81      0.80      0.81       496\n",
      "\n",
      "Recall : 77.25631768953069\n",
      "Precision : 86.29032258064517\n",
      "F1-Score : 81.52380952380953\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[432  36]\n",
      " [146 542]]\n",
      "Accuracy Score 84.2560553633218\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       468\n",
      "           1       0.94      0.79      0.86       688\n",
      "\n",
      "    accuracy                           0.84      1156\n",
      "   macro avg       0.84      0.86      0.84      1156\n",
      "weighted avg       0.86      0.84      0.84      1156\n",
      "\n",
      "************************************ ADA-Boost  Classifier *********************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[200   7]\n",
      " [ 48 241]]\n",
      "Accuracy Score 88.91129032258065\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       207\n",
      "           1       0.97      0.83      0.90       289\n",
      "\n",
      "    accuracy                           0.89       496\n",
      "   macro avg       0.89      0.90      0.89       496\n",
      "weighted avg       0.90      0.89      0.89       496\n",
      "\n",
      "Recall : 83.39100346020761\n",
      "Precision : 97.17741935483872\n",
      "F1-Score : 89.75791433891993\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[447  11]\n",
      " [131 567]]\n",
      "Accuracy Score 87.71626297577855\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.98      0.86       458\n",
      "           1       0.98      0.81      0.89       698\n",
      "\n",
      "    accuracy                           0.88      1156\n",
      "   macro avg       0.88      0.89      0.88      1156\n",
      "weighted avg       0.90      0.88      0.88      1156\n",
      "\n",
      "**************************************  Hyper-parameter ADA-BOOST **********************************************\n",
      "Confusion Matrix:\n",
      " [[199  10]\n",
      " [ 49 238]]\n",
      "Accuracy Score 88.10483870967742\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       209\n",
      "           1       0.96      0.83      0.89       287\n",
      "\n",
      "    accuracy                           0.88       496\n",
      "   macro avg       0.88      0.89      0.88       496\n",
      "weighted avg       0.89      0.88      0.88       496\n",
      "\n",
      "Recall : 82.92682926829268\n",
      "Precision : 95.96774193548387\n",
      "F1-Score : 88.97196261682242\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[454  12]\n",
      " [124 566]]\n",
      "Accuracy Score 88.23529411764706\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87       466\n",
      "           1       0.98      0.82      0.89       690\n",
      "\n",
      "    accuracy                           0.88      1156\n",
      "   macro avg       0.88      0.90      0.88      1156\n",
      "weighted avg       0.90      0.88      0.88      1156\n",
      "\n",
      "************************************ Naive-Bayes  Classifier *********************************************\n",
      "Confusion Matrix:\n",
      " [[179   3]\n",
      " [ 69 245]]\n",
      "Accuracy Score 85.48387096774194\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83       182\n",
      "           1       0.99      0.78      0.87       314\n",
      "\n",
      "    accuracy                           0.85       496\n",
      "   macro avg       0.85      0.88      0.85       496\n",
      "weighted avg       0.89      0.85      0.86       496\n",
      "\n",
      "Recall : 78.02547770700637\n",
      "Precision : 98.79032258064517\n",
      "F1-Score : 87.18861209964413\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[414   4]\n",
      " [164 574]]\n",
      "Accuracy Score 85.46712802768167\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.83       418\n",
      "           1       0.99      0.78      0.87       738\n",
      "\n",
      "    accuracy                           0.85      1156\n",
      "   macro avg       0.85      0.88      0.85      1156\n",
      "weighted avg       0.89      0.85      0.86      1156\n",
      "\n",
      "**************************************  Bernoulli Naive-Bayes  Classifier **********************************************\n",
      "Confusion Matrix:\n",
      " [[186  14]\n",
      " [ 62 234]]\n",
      "Accuracy Score 84.67741935483872\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       200\n",
      "           1       0.94      0.79      0.86       296\n",
      "\n",
      "    accuracy                           0.85       496\n",
      "   macro avg       0.85      0.86      0.85       496\n",
      "weighted avg       0.87      0.85      0.85       496\n",
      "\n",
      "Recall : 79.05405405405406\n",
      "Precision : 94.35483870967742\n",
      "F1-Score : 86.02941176470588\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[427  26]\n",
      " [151 552]]\n",
      "Accuracy Score 84.6885813148789\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       453\n",
      "           1       0.96      0.79      0.86       703\n",
      "\n",
      "    accuracy                           0.85      1156\n",
      "   macro avg       0.85      0.86      0.85      1156\n",
      "weighted avg       0.87      0.85      0.85      1156\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"************************************ SVM Classification *********************************************\")\n",
    "def SVM_clf(x_test,y_test,x_train,y_train):\n",
    "    svm_clf = SVC(random_state=5)\n",
    "    svm_clf.fit(x_train, y_train)\n",
    "    model_details.append(\"SVM Classification\")\n",
    "    # Testing Accuracy\n",
    "\n",
    "    y_pred = svm_clf.predict(x_test)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\", cnf_matrix)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\", clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    print(\"@\"*120)\n",
    "    # Training Accuracy\n",
    "\n",
    "    y_pred_train = svm_clf.predict(x_train)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\", cnf_matrix)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*55)\n",
    "    Training_accuracy.append(accuracy)\n",
    "\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\", clf_report)\n",
    "SVM_clf(x_test,y_test,x_train,y_train)  \n",
    "\n",
    "\n",
    "print(\"************************************ SVM with Hyperparameter  *********************************************\")  \n",
    "\n",
    "def SVM_clf_hyp(df):\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    std_scalar = StandardScaler()\n",
    "    std_scalar.fit(df1[x1])\n",
    "    array = std_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    \n",
    "    svm_clf_hyp = SVC(random_state=5)\n",
    "    model_details.append(\"SVM with Hyperparameter\")\n",
    "    \n",
    "    hyperparameters = {\"C\":np.arange(1,2),\n",
    "                      \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "    gscv_svm = GridSearchCV(svm_clf_hyp, hyperparameters, cv=5)\n",
    "    gscv_svm.fit(x_train, y_train)\n",
    "    gscv_svm.best_estimator_\n",
    "\n",
    "    svm_clf = gscv_svm.best_estimator_\n",
    "    svm_clf.fit(x_train, y_train)\n",
    "\n",
    "    # Testing Accuracy\n",
    "\n",
    "    y_pred = svm_clf.predict(x_test)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\", cnf_matrix)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    \n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\", clf_report)\n",
    "\n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    print(\"@\"*120)\n",
    "    # Training Accuracy\n",
    "\n",
    "    y_pred_train = svm_clf.predict(x_train)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\", cnf_matrix)\n",
    "    print(\"*\"*55)\n",
    "\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*55)\n",
    "    Training_accuracy.append(accuracy)\n",
    "\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\", clf_report)\n",
    "SVM_clf_hyp(df)\n",
    "\n",
    "print(\"************************************ SVM with Standard scalar*********************************************\")\n",
    "def svm_std_scalar(df):\n",
    "    \n",
    "       \n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    std_scalar = StandardScaler()\n",
    "    std_scalar.fit(df1[x1])\n",
    "    array = std_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    svm_std=SVC()\n",
    "    svm_std.fit(x_train,y_train)\n",
    "    model_details.append(\"SVM with Std Scaling\")\n",
    "    #Testing Data\n",
    "    y_pred = svm_std.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = svm_std.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "svm_std_scalar(df)\n",
    "\n",
    "print(\"************************************ SVM with normal scalar*********************************************\")\n",
    "\n",
    "\n",
    "def svm_MinMax_scalar(df):\n",
    "        \n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    normal_scalar = MinMaxScaler()\n",
    "    normal_scalar.fit(df1[x1])\n",
    "    array = normal_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    svm_normal = SVC(random_state=5)\n",
    "    svm_normal.fit(x_train,y_train)\n",
    "    model_details.append(\"SVM with Normal Scaling\")\n",
    "    #Testing Data\n",
    "    y_pred = svm_normal.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = svm_normal.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "svm_MinMax_scalar(df)\n",
    "\n",
    "\n",
    "print(\"************************************ Logistic Regression*********************************************\")\n",
    "def LOG_model(x_test,y_test,x_train,y_train):\n",
    "    lr_model=LogisticRegression(random_state=5)\n",
    "    lr_model.fit(x_train,y_train)\n",
    "    model_details.append(\"Logistic Regression\")\n",
    "    #Testing Data\n",
    "    y_pred = lr_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = lr_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)      \n",
    "LOG_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "print(\"************************************ K-Neighbours Regression*********************************************\")\n",
    "\n",
    "def KNN_model1(x_test,y_test,x_train,y_train):\n",
    "    knn_model=KNeighborsClassifier()\n",
    "    knn_model.fit(x_train,y_train)\n",
    "    model_details.append(\"K-Neighbours Classification Without Scaling\")\n",
    "    #Testing Data\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = knn_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "KNN_model1(x_test,y_test,x_train,y_train)\n",
    "\n",
    "print(\"************************************ K-Neighbours with std scalar *********************************************\")\n",
    "\n",
    "    \n",
    "def knn_std_scalar(df):\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    std_scalar = StandardScaler()\n",
    "    std_scalar.fit(df1[x1])\n",
    "    array = std_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    knn_model_std = KNeighborsClassifier()\n",
    "    knn_model_std.fit(x_train,y_train)\n",
    "    model_details.append(\"KNN with Std Scaling\")\n",
    "    #Testing Data\n",
    "    y_pred = knn_model_std.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = knn_model_std.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "knn_std_scalar(df)\n",
    "\n",
    "print(\"************************************ K-Neighbours with normal scalar*********************************************\")\n",
    "\n",
    "\n",
    "def knn_MinMax_scalar(df):\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    normal_scalar = MinMaxScaler()\n",
    "    normal_scalar.fit(df1[x1])\n",
    "    array = normal_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    knn_model_normal = KNeighborsClassifier()\n",
    "    knn_model_normal.fit(x_train,y_train)\n",
    "    model_details.append(\"KNN with Normal Scaling\")\n",
    "    #Testing Data\n",
    "    y_pred = knn_model_normal.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    #Training Data\n",
    "    y_pred_train = knn_model_normal.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "knn_MinMax_scalar(df)\n",
    "\n",
    "print(\"************************************** KNN-HyperParameter Tuning  **********************************************\")\n",
    "\n",
    "def hyper_parameter_knn(df):\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "    \n",
    "    std_scalar = StandardScaler()\n",
    "    std_scalar.fit(df1[x1])\n",
    "    array = std_scalar.transform(df1[x1])\n",
    "    x = pd.DataFrame(array, columns=x1)\n",
    "    for i in x1:\n",
    "        df1[i] = x[i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    target_column = \"Rating\"\n",
    "    x = df1.drop(target_column,axis=1)\n",
    "    y = df1[target_column]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "    \n",
    "    knn_clf=KNeighborsClassifier()        # estimator\n",
    "    hyperparameters = {\"n_neighbors\" : np.arange(3,30),\n",
    "                      \"p\": [1,2]}                                              # param-grid\n",
    "    gscv_knn_clf =GridSearchCV(knn_clf,hyperparameters,cv=5)\n",
    "    gscv_knn_clf.fit(x_train,y_train)\n",
    "    gscv_knn_clf.best_estimator_\n",
    "    gscv_knn_clf.best_params_\n",
    "    model_details.append(\"KNN-Hyperparameter_Tunning\")\n",
    "\n",
    "    #testing_accuracy\n",
    "    y_pred = gscv_knn_clf.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    \n",
    "    Testing_accuracy.append(accuracy)\n",
    "    \n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    #training_accuracy\n",
    "    y_pred_train = gscv_knn_clf.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "hyper_parameter_knn(df) \n",
    "\n",
    "print(\"************************************ Decision-Tree Regression*********************************************\")\n",
    "\n",
    "def tree_model(x_test,y_test,x_train,y_train):\n",
    "    dt_model=DecisionTreeClassifier(random_state=5)\n",
    "    dt_model.fit(x_train,y_train)\n",
    "    model_details.append(\"Decision-Tree Regression\")\n",
    "    #Testing Data\n",
    "    y_pred = dt_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    print(\"@\"*120)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = dt_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "tree_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "print(\"************************************** Pre_prunning Decision Tree  **********************************************\")\n",
    "\n",
    "def pre_pruning(x_train,y_train,x_test,y_test):\n",
    "    dt_clf = DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "    hyperparameter = {\"criterion\":['gini', 'entropy'],\n",
    "    'max_depth':np.arange(3,8),\n",
    "    'min_samples_split': np.arange(2,8),\n",
    "    'min_samples_leaf':np.arange(5,7)}\n",
    "\n",
    "    gscv_dt_clf_model = GridSearchCV(dt_clf, hyperparameter, cv = 5)\n",
    "    gscv_dt_clf_model.fit(x_train, y_train)\n",
    "\n",
    "    dt_clf_hp_model = gscv_dt_clf_model.best_estimator_\n",
    "    dt_clf_hp_model.fit(x_train, y_train)\n",
    "    model_details.append(\"Pre-Pruning DT Classifier\")\n",
    "    # Testing data\n",
    "    y_pred = dt_clf_hp_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "\n",
    "    print(\"*\"*45)\n",
    "    accuracy = accuracy_score(y_test, y_pred)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*45)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"*\"*90)\n",
    "\n",
    "    # Training data\n",
    "\n",
    "    # prediction\n",
    "    y_pred_train = dt_clf_hp_model.predict(x_train)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "\n",
    "    print(\"*\"*45)\n",
    "    accuracy = accuracy_score(y_train, y_pred_train)*100\n",
    "    print(\"Accuracy Score:\",accuracy)\n",
    "    print(\"*\"*45)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_train, y_pred_train)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "      \n",
    "pre_pruning(x_train,y_train,x_test,y_test)\n",
    "\n",
    "print(\"**************************************  Post Pruning-CCP Alpha DT **********************************************\")\n",
    "def post_pruning(x_train,y_train,x_test,y_test):\n",
    "    decision_tree = DecisionTreeClassifier(random_state=5)\n",
    "    decision_tree.fit(x_train, y_train)\n",
    "    result = decision_tree.cost_complexity_pruning_path(x_train, y_train)\n",
    "    ccp_alpha_list = result['ccp_alphas']\n",
    "    # ccp_alpha_list\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "\n",
    "    for i in ccp_alpha_list:\n",
    "        decision_tree = DecisionTreeClassifier(ccp_alpha= i,random_state=7)\n",
    "        decision_tree.fit(x_train, y_train)\n",
    "    \n",
    "        training_accuracy = decision_tree.score(x_train, y_train)\n",
    "        train_accuracy_list.append(training_accuracy)\n",
    "    \n",
    "        testing_Accuracy = decision_tree.score(x_test, y_test)\n",
    "        test_accuracy_list.append(testing_Accuracy)\n",
    "    \n",
    "   \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(ccp_alpha_list, train_accuracy_list, label = \"Training Data Accuracy\")\n",
    "    ax.plot(ccp_alpha_list, test_accuracy_list, label = \"Testing Data Accuracy\")\n",
    "    ax.legend()\n",
    "    index_ccp = test_accuracy_list.index(max(test_accuracy_list))\n",
    "    best_ccp = ccp_alpha_list[index_ccp]\n",
    "    decision_tree = DecisionTreeClassifier(ccp_alpha= best_ccp,random_state=7)\n",
    "    decision_tree.fit(x_train, y_train)\n",
    "    model_details.append(\"Post-Pruning DT Classifier\")\n",
    "    \n",
    "    y_pred = decision_tree.predict(x_test)\n",
    "    y_pred_train = decision_tree.predict(x_train)\n",
    "    #Testing Accuracy\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Accuracy\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report) \n",
    "    \n",
    "    \n",
    "post_pruning(x_train,y_train,x_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"************************************ Random- Forest  Regression*********************************************\")\n",
    "\n",
    "def forest_model(x_test,y_test,x_train,y_train):\n",
    "    rf_model=RandomForestClassifier(random_state=5)\n",
    "    rf_model.fit(x_train,y_train)\n",
    "    model_details.append(\"Random- Forest  Regression\")\n",
    "    #Testing Data\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = rf_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "forest_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "print(\"**************************************  Hyper-parameter Random-Forest **********************************************\")\n",
    "\n",
    "def Hyper_parameter_Random_Forest(x_train,y_train,x_test,y_test):\n",
    "    rf_model = RandomForestClassifier(random_state=5)\n",
    "    model_details.append(\"Random Forest with hyperparameter\")\n",
    "    hyperparameter = {\"n_estimators\":np.arange(99,102),\n",
    "                     \"criterion\":['gini','entropy'],\n",
    "                     'max_depth':np.arange(3,5),\n",
    "                     'min_samples_split': np.arange(5,7),\n",
    "                     'min_samples_leaf':np.arange(7,8),\n",
    "                     'max_features':['sqrt','log2'] }\n",
    "\n",
    "    gscv_rf_model = GridSearchCV(rf_model, hyperparameter, cv=5)\n",
    "    gscv_rf_model.fit(x_train,y_train)\n",
    "    y_pred = gscv_rf_model.predict(x_test)\n",
    "    y_pred_train = gscv_rf_model.predict(x_train)\n",
    "    #testing_accuracy\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    \n",
    "    Testing_accuracy.append(accuracy)\n",
    "    \n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #training_accuracy\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)   \n",
    "\n",
    "Hyper_parameter_Random_Forest(x_train,y_train,x_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"************************************ ADA-Boost  Classifier *********************************************\")\n",
    "\n",
    "def boost_model(x_test,y_test,x_train,y_train):\n",
    "    ada_model=AdaBoostClassifier(random_state=5)\n",
    "    ada_model.fit(x_train,y_train)\n",
    "    model_details.append(\"ADA-Boost  Classifier\")\n",
    "    #Testing Data\n",
    "    y_pred = ada_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = ada_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "boost_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "print(\"**************************************  Hyper-parameter ADA-BOOST **********************************************\")\n",
    "\n",
    "def Hyper_parameter_ada_boost(x_train,y_train,x_test,y_test):\n",
    "    ada_model = AdaBoostClassifier(random_state=5)\n",
    "\n",
    "    hyperparameter = {\"n_estimators\":np.arange(49,52),\n",
    "                        \"learning_rate\":np.arange(0, 2, 0.05)}\n",
    "    model_details.append(\"Hyper-parameter ADA-BOOST\")\n",
    "    gscv_clf_ab = GridSearchCV(ada_model, hyperparameter, cv=5)\n",
    "    gscv_clf_ab.fit(x_train, y_train)\n",
    "    gscv_clf_ab.best_estimator_\n",
    "    ada_model = gscv_clf_ab.best_estimator_\n",
    "    ada_model.fit(x_train, y_train)\n",
    "    y_pred = gscv_clf_ab.predict(x_test)\n",
    "    y_pred_train = gscv_clf_ab.predict(x_train)\n",
    "    #testing_accuracy\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    \n",
    "    Testing_accuracy.append(accuracy)\n",
    "    \n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #training_accuracy\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)   \n",
    "\n",
    "Hyper_parameter_ada_boost(x_train,y_train,x_test,y_test)\n",
    "\n",
    "\n",
    "print(\"************************************ Naive-Bayes  Classifier *********************************************\")\n",
    "\n",
    "def bayes_model(x_test,y_test,x_train,y_train):\n",
    "    nb_model=GaussianNB()\n",
    "    nb_model.fit(x_train,y_train)\n",
    "    model_details.append(\" Gaussian Naive-Bayes  Classifier\")\n",
    "    #Testing Data\n",
    "    y_pred = nb_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = nb_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "bayes_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"**************************************  Multinomial Naive-Bayes  Classifier **********************************************\")\n",
    "# def multi_bayes_model(x_test,y_test,x_train,y_train):\n",
    "#     mn_model=MultinomialNB()\n",
    "#     mn_model.fit(x_train,y_train)\n",
    "#     model_details.append(\" Multinomial Naive-Bayes  Classifier\")\n",
    "#     #Testing Data\n",
    "#     y_pred = mn_model.predict(x_test)\n",
    "#     cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "#     print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "#     accuracy = accuracy_score(y_pred, y_test)*100\n",
    "#     print(\"Accuracy Score\", accuracy)\n",
    "#     Testing_accuracy.append(accuracy)\n",
    "#     clf_report = classification_report(y_pred, y_test)\n",
    "#     print(\"Classification report:\\n\",clf_report)\n",
    "#     print(\"@\"*120)\n",
    "#     #Training Data\n",
    "#     y_pred_train = mn_model.predict(x_train)\n",
    "#     cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "#     print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "#     accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "#     print(\"Accuracy Score\", accuracy)\n",
    "#     Training_accuracy.append(accuracy)\n",
    "#     clf_report = classification_report(y_pred_train, y_train)\n",
    "#     print(\"Classification report:\\n\",clf_report)    \n",
    "# multi_bayes_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "\n",
    "print(\"**************************************  Bernoulli Naive-Bayes  Classifier **********************************************\")\n",
    "def Bernoulli_bayes_model(x_test,y_test,x_train,y_train):\n",
    "    bern_model=BernoulliNB()\n",
    "    bern_model.fit(x_train,y_train)\n",
    "    model_details.append(\" Bernoulli Naive-Bayes  Classifier\")\n",
    "    #Testing Data\n",
    "    y_pred = bern_model.predict(x_test)\n",
    "    cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred, y_test)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Testing_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred, y_test)\n",
    "    print(\"Classification report:\\n\",clf_report)\n",
    "    \n",
    "    recall = recall_score(y_pred,y_test)*100\n",
    "    print(\"Recall :\" ,recall)\n",
    "    Testing_Recall.append(recall)\n",
    "    \n",
    "    precision = precision_score(y_pred,y_test)*100\n",
    "    print(\"Precision :\",precision)\n",
    "    Testing_Precision.append(precision)\n",
    "    \n",
    "    F1_score = f1_score(y_pred,y_test)*100\n",
    "    print(\"F1-Score :\",F1_score)\n",
    "    Testing_F1_Score.append(F1_score)\n",
    "    \n",
    "    \n",
    "    print(\"@\"*120)\n",
    "    #Training Data\n",
    "    y_pred_train = bern_model.predict(x_train)\n",
    "    cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "    print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "    accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "    print(\"Accuracy Score\", accuracy)\n",
    "    Training_accuracy.append(accuracy)\n",
    "    clf_report = classification_report(y_pred_train, y_train)\n",
    "    print(\"Classification report:\\n\",clf_report)    \n",
    "Bernoulli_bayes_model(x_test,y_test,x_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "64b84ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_details---->\n",
      " ['SVM Classification', 'SVM with Hyperparameter', 'SVM with Std Scaling', 'SVM with Normal Scaling', 'Logistic Regression', 'K-Neighbours Classification Without Scaling', 'KNN with Std Scaling', 'KNN with Normal Scaling', 'KNN-Hyperparameter_Tunning', 'Decision-Tree Regression', 'Pre-Pruning DT Classifier', 'Post-Pruning DT Classifier', 'Random- Forest  Regression', 'Random Forest with hyperparameter', 'ADA-Boost  Classifier', 'Hyper-parameter ADA-BOOST', ' Gaussian Naive-Bayes  Classifier', ' Bernoulli Naive-Bayes  Classifier']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing_accuracy----->\n",
      " [56.85483870967742, 89.51612903225806, 88.10483870967742, 89.51612903225806, 87.09677419354838, 66.73387096774194, 80.44354838709677, 84.67741935483872, 81.04838709677419, 79.23387096774194, 77.01612903225806, 84.07258064516128, 87.29838709677419, 80.44354838709677, 88.91129032258065, 88.10483870967742, 85.48387096774194, 84.67741935483872]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training_accuracy----->\n",
      " [55.79584775086506, 88.23529411764706, 87.5432525951557, 88.58131487889274, 87.62975778546713, 77.76816608996539, 88.92733564013841, 90.22491349480968, 91.00346020761245, 100.0, 80.88235294117648, 89.18685121107266, 100.0, 84.2560553633218, 87.71626297577855, 88.23529411764706, 85.46712802768167, 84.6885813148789]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing_Recall------>\n",
      " [57.798165137614674, 82.66666666666667, 81.1881188118812, 83.1081081081081, 79.48717948717949, 70.24390243902438, 86.82926829268293, 85.53719008264463, 87.37864077669903, 83.41013824884793, 77.01612903225806, 81.18081180811808, 85.44061302681992, 77.25631768953069, 83.39100346020761, 82.92682926829268, 78.02547770700637, 79.05405405405406]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing_Precision------>\n",
      " [50.806451612903224, 100.0, 99.19354838709677, 99.19354838709677, 100.0, 58.06451612903226, 71.7741935483871, 83.46774193548387, 72.58064516129032, 72.98387096774194, 77.01612903225806, 88.70967741935483, 89.91935483870968, 86.29032258064517, 97.17741935483872, 95.96774193548387, 98.79032258064517, 94.35483870967742]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing_F1_Score----->\n",
      " [54.07725321888412, 90.51094890510949, 89.29219600725953, 90.44117647058823, 88.57142857142858, 63.576158940397356, 78.58719646799118, 84.48979591836734, 79.29515418502203, 77.84946236559142, 77.01612903225806, 84.77842003853564, 87.62278978388998, 81.52380952380953, 89.75791433891993, 88.97196261682242, 87.18861209964413, 86.02941176470588]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(\"model_details---->\\n\",model_details) \n",
    "print(\"~\"*125)\n",
    "print(\"Testing_accuracy----->\\n\",Testing_accuracy) \n",
    "print(\"~\"*125)\n",
    "print(\"Training_accuracy----->\\n\",Training_accuracy) \n",
    "print(\"~\"*125)\n",
    "print(\"Testing_Recall------>\\n\",Testing_Recall) \n",
    "print(\"~\"*125)\n",
    "print(\"Testing_Precision------>\\n\",Testing_Precision) \n",
    "print(\"~\"*125)\n",
    "print(\"Testing_F1_Score----->\\n\",Testing_F1_Score) \n",
    "print(\"~\"*125)\n",
    " \n",
    "print(len(model_details))\n",
    "print(len(Testing_accuracy))\n",
    "print(len(Training_accuracy)) \n",
    "print(len(Testing_Recall))\n",
    "print(len(Testing_Precision))\n",
    "print(len(Testing_F1_Score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88ba3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8b2f12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Difference_Df=pd.DataFrame({\"Model_Details\":model_details,\n",
    "               \"Testing_Accuracy\":Testing_accuracy,\n",
    "               \"Training_Accuracy\":Training_accuracy,\n",
    "                \"Testing_Recall\":Testing_Recall,\n",
    "                \"Testing_Precision\":Testing_Precision,\n",
    "                \"Testing_F1_Score\":Testing_F1_Score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "16b85f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Details</th>\n",
       "      <th>Testing_Accuracy</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Testing_Recall</th>\n",
       "      <th>Testing_Precision</th>\n",
       "      <th>Testing_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Classification</td>\n",
       "      <td>56.854839</td>\n",
       "      <td>55.795848</td>\n",
       "      <td>57.798165</td>\n",
       "      <td>50.806452</td>\n",
       "      <td>54.077253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM with Hyperparameter</td>\n",
       "      <td>89.516129</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.510949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM with Std Scaling</td>\n",
       "      <td>88.104839</td>\n",
       "      <td>87.543253</td>\n",
       "      <td>81.188119</td>\n",
       "      <td>99.193548</td>\n",
       "      <td>89.292196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM with Normal Scaling</td>\n",
       "      <td>89.516129</td>\n",
       "      <td>88.581315</td>\n",
       "      <td>83.108108</td>\n",
       "      <td>99.193548</td>\n",
       "      <td>90.441176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>87.096774</td>\n",
       "      <td>87.629758</td>\n",
       "      <td>79.487179</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Neighbours Classification Without Scaling</td>\n",
       "      <td>66.733871</td>\n",
       "      <td>77.768166</td>\n",
       "      <td>70.243902</td>\n",
       "      <td>58.064516</td>\n",
       "      <td>63.576159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN with Std Scaling</td>\n",
       "      <td>80.443548</td>\n",
       "      <td>88.927336</td>\n",
       "      <td>86.829268</td>\n",
       "      <td>71.774194</td>\n",
       "      <td>78.587196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN with Normal Scaling</td>\n",
       "      <td>84.677419</td>\n",
       "      <td>90.224913</td>\n",
       "      <td>85.537190</td>\n",
       "      <td>83.467742</td>\n",
       "      <td>84.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN-Hyperparameter_Tunning</td>\n",
       "      <td>81.048387</td>\n",
       "      <td>91.003460</td>\n",
       "      <td>87.378641</td>\n",
       "      <td>72.580645</td>\n",
       "      <td>79.295154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision-Tree Regression</td>\n",
       "      <td>79.233871</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.410138</td>\n",
       "      <td>72.983871</td>\n",
       "      <td>77.849462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pre-Pruning DT Classifier</td>\n",
       "      <td>77.016129</td>\n",
       "      <td>80.882353</td>\n",
       "      <td>77.016129</td>\n",
       "      <td>77.016129</td>\n",
       "      <td>77.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Post-Pruning DT Classifier</td>\n",
       "      <td>84.072581</td>\n",
       "      <td>89.186851</td>\n",
       "      <td>81.180812</td>\n",
       "      <td>88.709677</td>\n",
       "      <td>84.778420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random- Forest  Regression</td>\n",
       "      <td>87.298387</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.440613</td>\n",
       "      <td>89.919355</td>\n",
       "      <td>87.622790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest with hyperparameter</td>\n",
       "      <td>80.443548</td>\n",
       "      <td>84.256055</td>\n",
       "      <td>77.256318</td>\n",
       "      <td>86.290323</td>\n",
       "      <td>81.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ADA-Boost  Classifier</td>\n",
       "      <td>88.911290</td>\n",
       "      <td>87.716263</td>\n",
       "      <td>83.391003</td>\n",
       "      <td>97.177419</td>\n",
       "      <td>89.757914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hyper-parameter ADA-BOOST</td>\n",
       "      <td>88.104839</td>\n",
       "      <td>88.235294</td>\n",
       "      <td>82.926829</td>\n",
       "      <td>95.967742</td>\n",
       "      <td>88.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gaussian Naive-Bayes  Classifier</td>\n",
       "      <td>85.483871</td>\n",
       "      <td>85.467128</td>\n",
       "      <td>78.025478</td>\n",
       "      <td>98.790323</td>\n",
       "      <td>87.188612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bernoulli Naive-Bayes  Classifier</td>\n",
       "      <td>84.677419</td>\n",
       "      <td>84.688581</td>\n",
       "      <td>79.054054</td>\n",
       "      <td>94.354839</td>\n",
       "      <td>86.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model_Details  Testing_Accuracy  \\\n",
       "0                            SVM Classification         56.854839   \n",
       "1                       SVM with Hyperparameter         89.516129   \n",
       "2                          SVM with Std Scaling         88.104839   \n",
       "3                       SVM with Normal Scaling         89.516129   \n",
       "4                           Logistic Regression         87.096774   \n",
       "5   K-Neighbours Classification Without Scaling         66.733871   \n",
       "6                          KNN with Std Scaling         80.443548   \n",
       "7                       KNN with Normal Scaling         84.677419   \n",
       "8                    KNN-Hyperparameter_Tunning         81.048387   \n",
       "9                      Decision-Tree Regression         79.233871   \n",
       "10                    Pre-Pruning DT Classifier         77.016129   \n",
       "11                   Post-Pruning DT Classifier         84.072581   \n",
       "12                   Random- Forest  Regression         87.298387   \n",
       "13            Random Forest with hyperparameter         80.443548   \n",
       "14                        ADA-Boost  Classifier         88.911290   \n",
       "15                    Hyper-parameter ADA-BOOST         88.104839   \n",
       "16             Gaussian Naive-Bayes  Classifier         85.483871   \n",
       "17            Bernoulli Naive-Bayes  Classifier         84.677419   \n",
       "\n",
       "    Training_Accuracy  Testing_Recall  Testing_Precision  Testing_F1_Score  \n",
       "0           55.795848       57.798165          50.806452         54.077253  \n",
       "1           88.235294       82.666667         100.000000         90.510949  \n",
       "2           87.543253       81.188119          99.193548         89.292196  \n",
       "3           88.581315       83.108108          99.193548         90.441176  \n",
       "4           87.629758       79.487179         100.000000         88.571429  \n",
       "5           77.768166       70.243902          58.064516         63.576159  \n",
       "6           88.927336       86.829268          71.774194         78.587196  \n",
       "7           90.224913       85.537190          83.467742         84.489796  \n",
       "8           91.003460       87.378641          72.580645         79.295154  \n",
       "9          100.000000       83.410138          72.983871         77.849462  \n",
       "10          80.882353       77.016129          77.016129         77.016129  \n",
       "11          89.186851       81.180812          88.709677         84.778420  \n",
       "12         100.000000       85.440613          89.919355         87.622790  \n",
       "13          84.256055       77.256318          86.290323         81.523810  \n",
       "14          87.716263       83.391003          97.177419         89.757914  \n",
       "15          88.235294       82.926829          95.967742         88.971963  \n",
       "16          85.467128       78.025478          98.790323         87.188612  \n",
       "17          84.688581       79.054054          94.354839         86.029412  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Difference_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a598ecd",
   "metadata": {},
   "source": [
    "# Testing on single row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e784be02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Quantity', 'Total', 'cogs', 'Branch_A', 'Branch_B',\n",
       "       'Branch_C', 'City_Mandalay', 'City_Naypyitaw', 'City_Yangon',\n",
       "       'Customer_type', 'Unit_price', 'Tax_5', 'gross_income',\n",
       "       'Product_line_Electronic accessories',\n",
       "       'Product_line_Fashion accessories', 'Product_line_Food and beverages',\n",
       "       'Product_line_Health and beauty', 'Product_line_Home and lifestyle',\n",
       "       'Product_line_Sports and travel', 'Payment_Cash', 'Payment_Credit card',\n",
       "       'Payment_Ewallet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = x.columns\n",
    "len(column_names)\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "99c3ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_column = [\"Branch\",\"City\",\"Product_line\",\"Payment\"]\n",
    "label_encoded_column = [\"Customer_type\",\"Gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "47f5f264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0, 'Member': 1}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Customer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f1fed371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Female': 0, 'Male': 1}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d4eb943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>7.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>548.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cogs</th>\n",
       "      <td>522.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branch_A</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branch_B</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Branch_C</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Mandalay</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Naypyitaw</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Yangon</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer_type</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unit_price</th>\n",
       "      <td>74.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tax_5</th>\n",
       "      <td>26.1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross_income</th>\n",
       "      <td>26.1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Electronic accessories</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Fashion accessories</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Food and beverages</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Health and beauty</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Home and lifestyle</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_line_Sports and travel</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Cash</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Credit card</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payment_Ewallet</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "Gender                                 0.0000\n",
       "Quantity                               7.0000\n",
       "Total                                548.9715\n",
       "cogs                                 522.8300\n",
       "Branch_A                               1.0000\n",
       "Branch_B                               0.0000\n",
       "Branch_C                               0.0000\n",
       "City_Mandalay                          0.0000\n",
       "City_Naypyitaw                         0.0000\n",
       "City_Yangon                            1.0000\n",
       "Customer_type                          1.0000\n",
       "Unit_price                            74.6900\n",
       "Tax_5                                 26.1415\n",
       "gross_income                          26.1415\n",
       "Product_line_Electronic accessories    0.0000\n",
       "Product_line_Fashion accessories       0.0000\n",
       "Product_line_Food and beverages        0.0000\n",
       "Product_line_Health and beauty         1.0000\n",
       "Product_line_Home and lifestyle        0.0000\n",
       "Product_line_Sports and travel         0.0000\n",
       "Payment_Cash                           0.0000\n",
       "Payment_Credit card                    0.0000\n",
       "Payment_Ewallet                        1.0000"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "3d2576e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = 'Male'\n",
    "Quantity = 7.0000\n",
    "Total = 548.9715\n",
    "cogs = 522.8300\n",
    "\n",
    "\n",
    "\n",
    "Customer_type = 'Normal'\n",
    "Unit_price = 74.6900\n",
    "Tax_5 = 26.1415\n",
    "gross_income = 26.1415\n",
    "\n",
    "# one hot encodded column \n",
    "Product_line = \"Electronic accessories\"\n",
    "Payment = \"Ewallet\"\n",
    "Branch = \"A\"\n",
    "City = \"Yangon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "123d1ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_line_Electronic accessories\n",
      "Payment_Ewallet\n",
      "Branch_A\n",
      "City_Yangon\n"
     ]
    }
   ],
   "source": [
    "## Define column name\n",
    "Product_line_col = \"Product_line_\" + Product_line\n",
    "Payment_col = \"Payment_\" + Payment \n",
    "Branch_col = \"Branch_\" + Branch\n",
    "City_col = \"City_\" + City\n",
    "\n",
    "print(Product_line_col)\n",
    "print(Payment_col)\n",
    "print(Branch_col)\n",
    "print(City_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "342fe80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "22\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "Product_line_index = np.where (column_names == Product_line_col)[0][0]\n",
    "Payment_index = np.where(column_names == Payment_col)[0][0]\n",
    "Branch_index = np.where(column_names == Branch_col)[0][0]\n",
    "City_index = np.where(column_names == City_col)[0][0]\n",
    "\n",
    "print(Product_line_index)\n",
    "print(Payment_index)\n",
    "print(Branch_index)\n",
    "print(City_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "516ee09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.zeros(len(column_names),dtype=int)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "82da8eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Quantity', 'Total', 'cogs', 'Branch_A', 'Branch_B',\n",
       "       'Branch_C', 'City_Mandalay', 'City_Naypyitaw', 'City_Yangon',\n",
       "       'Customer_type', 'Unit_price', 'Tax_5', 'gross_income',\n",
       "       'Product_line_Electronic accessories',\n",
       "       'Product_line_Fashion accessories', 'Product_line_Food and beverages',\n",
       "       'Product_line_Health and beauty', 'Product_line_Home and lifestyle',\n",
       "       'Product_line_Sports and travel', 'Payment_Cash', 'Payment_Credit card',\n",
       "       'Payment_Ewallet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "cfad5470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0] = values_Customer_type[Customer_type]\n",
    "array[1] = values_Gender[Gender]\n",
    "array[2] = Unit_price\n",
    "array[3] = Quantity\n",
    "array[4] = Tax_5\n",
    "array[5] = Total\n",
    "array[6] = cogs\n",
    "array[7] = gross_income\n",
    "\n",
    "\n",
    "\n",
    "array[Product_line_index] = 1\n",
    "array[Payment_index] = 1\n",
    "array[Branch_index] = 1\n",
    "array[City_index] = 1\n",
    "\n",
    "array\n",
    "len(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d5c63",
   "metadata": {},
   "source": [
    "# Best accuracy model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "35f2d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[198   2]\n",
      " [ 50 246]]\n",
      "Accuracy Score 89.51612903225806\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       200\n",
      "           1       0.99      0.83      0.90       296\n",
      "\n",
      "    accuracy                           0.90       496\n",
      "   macro avg       0.90      0.91      0.89       496\n",
      "weighted avg       0.91      0.90      0.90       496\n",
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Recall : 83.1081081081081\n",
      "Precision : 99.19354838709677\n",
      "F1-Score : 90.44117647058823\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "Confusion Matrix:\n",
      " [[446   0]\n",
      " [132 578]]\n",
      "Accuracy Score 88.58131487889274\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       446\n",
      "           1       1.00      0.81      0.90       710\n",
      "\n",
      "    accuracy                           0.89      1156\n",
      "   macro avg       0.89      0.91      0.88      1156\n",
      "weighted avg       0.91      0.89      0.89      1156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def svm_MinMax_scalar(df):\n",
    "        \n",
    "df1 = df.copy()\n",
    "\n",
    "x1 = ['Unit_price','Quantity','Tax_5','Total','cogs','gross_income']\n",
    "\n",
    "normal_scalar = MinMaxScaler()\n",
    "normal_scalar.fit(df1[x1])\n",
    "array1 = normal_scalar.transform(df1[x1])\n",
    "x = pd.DataFrame(array1, columns=x1)\n",
    "for i in x1:\n",
    "    df1[i] = x[i]\n",
    "\n",
    "\n",
    "\n",
    "target_column = \"Rating\"\n",
    "x = df1.drop(target_column,axis=1)\n",
    "y = df1[target_column]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y , test_size=0.3, random_state=10, stratify=y)\n",
    "\n",
    "svm_normal = SVC(random_state=5)\n",
    "svm_normal.fit(x_train,y_train)\n",
    "#     model_details.append(\"SVM with Normal Scaling\")\n",
    "#Testing Data\n",
    "y_pred = svm_normal.predict(x_test)\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "accuracy = accuracy_score(y_pred, y_test)*100\n",
    "print(\"Accuracy Score\", accuracy)\n",
    "#     Testing_accuracy.append(accuracy)\n",
    "clf_report = classification_report(y_pred, y_test)\n",
    "print(\"Classification report:\\n\",clf_report)\n",
    "print(\"@\"*120)\n",
    "\n",
    "recall = recall_score(y_pred,y_test)*100\n",
    "print(\"Recall :\" ,recall)\n",
    "#     Testing_Recall.append(recall)\n",
    "\n",
    "precision = precision_score(y_pred,y_test)*100\n",
    "print(\"Precision :\",precision)\n",
    "#     Testing_Precision.append(precision)\n",
    "\n",
    "F1_score = f1_score(y_pred,y_test)*100\n",
    "print(\"F1-Score :\",F1_score)\n",
    "#     Testing_F1_Score.append(F1_score)\n",
    "\n",
    "print(\"@\"*120)\n",
    "#Training Data\n",
    "y_pred_train = svm_normal.predict(x_train)\n",
    "cnf_matrix = confusion_matrix(y_pred_train, y_train)\n",
    "print(\"Confusion Matrix:\\n\",cnf_matrix)\n",
    "accuracy = accuracy_score(y_pred_train, y_train)*100\n",
    "print(\"Accuracy Score\", accuracy)\n",
    "#     Training_accuracy.append(accuracy)\n",
    "clf_report = classification_report(y_pred_train, y_train)\n",
    "print(\"Classification report:\\n\",clf_report)    \n",
    "# svm_MinMax_scalar(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b9bdf1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "prediction = svm_normal.predict([array])[0]\n",
    "print(prediction)\n",
    "if prediction == 1:\n",
    "    print(\"Customer is satisfied \")\n",
    "else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "ccc2133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "0d939aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Customer_type': 'Normal',\n",
       " 'Gender': 'Male',\n",
       " 'column_name': ['Gender',\n",
       "  'Quantity',\n",
       "  'Total',\n",
       "  'cogs',\n",
       "  'Branch_A',\n",
       "  'Branch_B',\n",
       "  'Branch_C',\n",
       "  'City_Mandalay',\n",
       "  'City_Naypyitaw',\n",
       "  'City_Yangon',\n",
       "  'Customer_type',\n",
       "  'Unit_price',\n",
       "  'Tax_5',\n",
       "  'gross_income',\n",
       "  'Product_line_Electronic accessories',\n",
       "  'Product_line_Fashion accessories',\n",
       "  'Product_line_Food and beverages',\n",
       "  'Product_line_Health and beauty',\n",
       "  'Product_line_Home and lifestyle',\n",
       "  'Product_line_Sports and travel',\n",
       "  'Payment_Cash',\n",
       "  'Payment_Credit card',\n",
       "  'Payment_Ewallet']}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_dict = {\"Customer_type\":Customer_type,\n",
    "              \"Gender\":Gender,\n",
    "              \"column_name\":list(column_names)}\n",
    "column_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0603ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"column_dict.json\", \"w\") as f:\n",
    "    json.dump(column_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model in Pickle File\n",
    "import pickle\n",
    "\n",
    "with open(\"svm_normal.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm_normal, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0edaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807cd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd60c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e627ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a32ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a93451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89798fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828c116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38991f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3658f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d83b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824af3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198f855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb87bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
